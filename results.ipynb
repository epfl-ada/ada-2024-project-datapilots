{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c53cdf",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c60b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime, date, time\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import scipy.stats as st\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aa32a7",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd63950a",
   "metadata": {},
   "source": [
    "The dataset used in this analysis consists of beer reviews from two beer rating websites,**BeerAdvocate** and **RateBeer**, for a period ranging from 2001 to 2017. For each website, we have 5 files:\n",
    "- users.csv: metadata about reviewers\n",
    "- beers.csv : metadata about reviewed beers\n",
    "- breweries.csv : metadata about breweries\n",
    "- ratings.txt : all reviews given by users, including numerical ratings and sometimes textual reviews\n",
    "- reviews.txt : only reviews given by users that include both numerical ratings and textual reviews\n",
    "\n",
    "In our analysis, we will not use textual reviews. Thus, we will only use ratings.txt files and not reviews.txt files, as we will use all reviews, whether or not they include textual reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f5967d",
   "metadata": {},
   "source": [
    "### Load data into Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea7de26",
   "metadata": {},
   "source": [
    "The .csv files are not too large and can efficiently be loaded into DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29362fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "BA_DATA_FOLDER = 'data/BeerAdvocate/'\n",
    "RB_DATA_FOLDER = 'data/RateBeer/'\n",
    "\n",
    "BA_USERS = BA_DATA_FOLDER+\"users.csv\"\n",
    "BA_BEERS = BA_DATA_FOLDER+\"beers.csv\"\n",
    "BA_BREWERIES = BA_DATA_FOLDER+\"breweries.csv\"\n",
    "\n",
    "RB_USERS = RB_DATA_FOLDER+\"users.csv\"\n",
    "RB_BEERS = RB_DATA_FOLDER+\"beers.csv\"\n",
    "RB_BREWERIES = RB_DATA_FOLDER+\"breweries.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d5750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_users = pd.read_csv(BA_USERS)\n",
    "ba_beers = pd.read_csv(BA_BEERS)\n",
    "ba_breweries = pd.read_csv(BA_BREWERIES)\n",
    "\n",
    "rb_users = pd.read_csv(RB_USERS)\n",
    "rb_beers = pd.read_csv(RB_BEERS)\n",
    "rb_breweries = pd.read_csv(RB_BREWERIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9de82ff",
   "metadata": {},
   "source": [
    "On the other hand, the ratings.txt files are extremely large, and trying to load them directly into DataFrames leads to kernel freezes. In order to circumvent this problem, we wrote a script (review_parser.py, located in src/scripts), which processes each rating file by dividing it into parts, parsing each part, and saving as JSON. In the notebook, we then load the different JSON files into DataFrames, that we concatenate. Dividing the large .txt files into smaller JSON chunks and then loading each chunk separately, avoids trying to load the entire file into memory at once, which can cause kernel freezes due to memory overload. In addition, JSON is a format that pandas can read efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea3c0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orkun\\AppData\\Local\\Temp\\ipykernel_29228\\3299018877.py:3: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  ba_df_list = [pd.read_json(file) for file in ba_json_files]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      2\u001b[0m ba_json_files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(BA_DATA_FOLDER\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m ba_df_list \u001b[38;5;241m=\u001b[39m [pd\u001b[38;5;241m.\u001b[39mread_json(file) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m ba_json_files]\n\u001b[0;32m      4\u001b[0m ba_ratings \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(ba_df_list, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m ba_json_files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(BA_DATA_FOLDER\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m ba_df_list \u001b[38;5;241m=\u001b[39m [\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m ba_json_files]\n\u001b[0;32m      4\u001b[0m ba_ratings \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(ba_df_list, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py:784\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py:975\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 975\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py:1001\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1001\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py:1134\u001b[0m, in \u001b[0;36mParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 1134\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py:1319\u001b[0m, in \u001b[0;36mFrameParser._parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1319\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:782\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    781\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m--> 782\u001b[0m arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    790\u001b[0m mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    791\u001b[0m     arrays,\n\u001b[0;32m    792\u001b[0m     columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    795\u001b[0m     typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    796\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:498\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    496\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[1;32m--> 498\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    499\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:832\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data[\u001b[38;5;241m0\u001b[39m], abc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m--> 832\u001b[0m     arr, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_list_of_dict_to_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:912\u001b[0m, in \u001b[0;36m_list_of_dict_to_arrays\u001b[1;34m(data, columns)\u001b[0m\n\u001b[0;32m    911\u001b[0m sort \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(d, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[1;32m--> 912\u001b[0m pre_cols \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_unique_multiple_list_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    913\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(pre_cols)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:374\u001b[0m, in \u001b[0;36mpandas._libs.lib.fast_unique_multiple_list_gen\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:910\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 910\u001b[0m     gen \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlist\u001b[39m(x\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[0;32m    911\u001b[0m     sort \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(d, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load BeerAdvocate ratings stored in json files into a single DataFrame\n",
    "ba_json_files = glob.glob(BA_DATA_FOLDER+'*.json')\n",
    "ba_df_list = [pd.read_json(file) for file in ba_json_files]\n",
    "ba_ratings = pd.concat(ba_df_list, ignore_index=True)\n",
    "ba_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad45bd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load RateBeer ratings stored in json files into a single DataFrame\n",
    "rb_json_files = glob.glob(RB_DATA_FOLDER+'*.json')\n",
    "rb_df_list = [pd.read_json(file) for file in rb_json_files]\n",
    "rb_ratings = pd.concat(rb_df_list, ignore_index=True)\n",
    "rb_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0df2769",
   "metadata": {},
   "source": [
    "### First look at the data\n",
    "\n",
    "We will now examine the different DataFrames in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4aa33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain the columns of users, beers, breweries and ratings DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883544be",
   "metadata": {},
   "source": [
    "**BeerAdvocate beer Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88626551",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_beers.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b9da71",
   "metadata": {},
   "source": [
    "Let us explain the different columns of the BeerAdvocate beer Dataframe, in which each row is a beer:\n",
    "- beer_id, beer_name, brewery_id, brewery_name, style are explicit\n",
    "- nbr_ratings: total number of reviews for that beer, whether or not they include textual reviews\n",
    "- nbr_reviews: number of reviews for that beer that include textual reviews\n",
    "- avg: average rating (out of 5) given to the beer based on user ratings\n",
    "- ba_score: the BeerAdvocate score assigned to the beer, which corresponds to the beer's overall rating within its style category, calculated using a trimmed mean and a custom Bayesian formula that adjusts for the beer's style, balancing the score based on the number of ratings and the style's average\n",
    "- bros_score: beer rating given by the site’s founders\n",
    "- abv: 'Alcohol by volume', which indicates the percentage of alcohol content in the beer\n",
    "- avg_computed: average rating (out of 5) recalculated using a weighted sum of the different aspect ratings\n",
    "- zscore: z-score of the beer's average rating, which is a statistical measure that indicates how many standard deviations the average rating is from the mean of all ratings from the BeerAdvocate dataset\n",
    "- nbr_matched_valid_ratings: number of valid ratings for beers that were successfully matched between two BeerAdvocate and RateBeer\n",
    "- avg_matched_valid_ratings: average rating of those matched and valid ratings across the sites\n",
    "\n",
    "The last two columns are related to the analysis performed by Robert West and Gael Lederrey in the following paper: https://dlab.epfl.ch/people/west/pub/Lederrey-West_WWW-18.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61ba0d8",
   "metadata": {},
   "source": [
    "**RateBeer beer Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f856a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_beers.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde8a37e",
   "metadata": {},
   "source": [
    "Let us explain the different columns of the RateBeer beer Dataframe, in which each row is a beer:\n",
    "\n",
    "The beer_id, beer_name, brewery_id, brewery_name, style, nbr_ratings, avg, abv, avg_computed, z-score, nbr_matched_valid_ratings and avg_matched_valid_ratings are the same as for the BeerAdvocate beer Dataframe.\n",
    "\n",
    "Some columns are missing compared to the BeerAdvocate beer Dataframe: ba_score and bros_score (which makes sense as these are BeerAdvocate-specific scores), and nbr_reviews.\n",
    "\n",
    "New columns are present compared to the BeerAdvocate beer Dataframe:\n",
    "- overall_score: score (out of 100) which \"reflects the rating given by RateBeer users and how this beer compares to all other beers on RateBeer\", calculated by considering the ratings given by each user and the total number of ratings for the beer\n",
    "- style_score: score given to the beer (out of 100) specifically within its style category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c05b97f",
   "metadata": {},
   "source": [
    "**BeerAdvocate user Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39afb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_users.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aa2be4",
   "metadata": {},
   "source": [
    "Let us explain the different columns of the BeerAdvocate user Dataframe, in which each row is a reviewer:\n",
    "- nbr_ratings, nbr_reviews, user_id, user_name, and location are explicit\n",
    "- joined: timestamp indicating when the user joined BeerAdvocate in Unix timestamp format (the number of seconds since January 1, 1970, 00:00:00 UTC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b3a61b",
   "metadata": {},
   "source": [
    "**RateBeer user Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eed828",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_users.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabbb83a",
   "metadata": {},
   "source": [
    "Let us explain the different columns of the RateBeer user Dataframe, in which each row is a reviewer:\n",
    "\n",
    "The columns are the same as in the BeerAdvocate user Dataframe (joined is obviously the timestamp indicating when the user joined RateBeer and not BeerAdvocate), except that nbr_reviews is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f6da89",
   "metadata": {},
   "source": [
    "**Brewery Dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3b5830",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_breweries.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0d1708",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_breweries.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc5c713",
   "metadata": {},
   "source": [
    "The columns are explicit and are the same for the 2 websites. Each row is a brewery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0984a9c",
   "metadata": {},
   "source": [
    "**Rating Dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5201a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_ratings.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87f6a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_ratings.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba82d2b5",
   "metadata": {},
   "source": [
    "The columns are the same for the 2 Dataframes. Each row corresponds to an individual review. Most column names are explicit. \n",
    "- 'appearance','aroma', 'palate','taste' correspond to aspect ratings (out of 5)\n",
    "- 'overall' is the mean of the 4 aspect ratings\n",
    "- 'rating' is the final rating given by the user to the beer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d66d8a6",
   "metadata": {},
   "source": [
    "# 0) Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa61cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove useless columns (done)\n",
    "# make sure each column has the right type (done)\n",
    "# deal with missing or Nan values (done)\n",
    "# check the correspondance between brewery_id in the beers DataFrames and brewery_id in the breweries Dataframes (done)\n",
    "# set all US locations to 'United States' (remove state information) (done)\n",
    "# remove any embedded HTML links in the location strings (done)\n",
    "# remove countries with too few reviewers (done)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec00b50",
   "metadata": {},
   "source": [
    "## Filtering Dataframes\n",
    "\n",
    "Let us start by removing columns in the different Dataframes that we will not use in our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7166457",
   "metadata": {},
   "source": [
    "The following rows will not be used in our analysis:\n",
    "nbr_reviews, ba_score, bros_score, abv, avg_computed, zscore, nbr_matched_valid_ratings and avg_matched_valid_ratings, overall_score and style_score.\n",
    "\n",
    "Let us remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c7439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_columns_ba = ['nbr_reviews', 'ba_score', 'bros_score', 'abv', 'avg_computed', 'zscore', 'nbr_matched_valid_ratings', 'avg_matched_valid_ratings']\n",
    "ba_beers = ba_beers.drop(columns=useless_columns_ba)\n",
    "print(ba_beers.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa124cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_columns_rb = [col for col in useless_columns_ba if col not in ['nbr_reviews','ba_score', 'bros_score']] + ['overall_score', 'style_score']\n",
    "rb_beers = rb_beers.drop(columns=useless_columns_rb)\n",
    "print(rb_beers.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47725142",
   "metadata": {},
   "source": [
    "We will also not use the timestamps indicating the time when users joined the platforms, so let us remove this as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97382d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_users = ba_users.drop(columns='joined')\n",
    "rb_users = rb_users.drop(columns='joined')\n",
    "print(ba_users.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673f07e8",
   "metadata": {},
   "source": [
    "## Verifying value types\n",
    "\n",
    "Let us verify that the values in the different columns of the different Dataframes have the appropriate type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd8933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ba_beers.dtypes,'\\n','\\n',rb_beers.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eb84ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ba_users.dtypes,'\\n','\\n',rb_users.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d4f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ba_breweries.dtypes,'\\n','\\n',rb_breweries.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ff32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = ['beer_name', 'brewery_name', 'style']\n",
    "\n",
    "ba_beers[columns_to_convert] = ba_beers[columns_to_convert].apply(lambda col: col.astype(str))\n",
    "rb_beers[columns_to_convert] = rb_beers[columns_to_convert].apply(lambda col: col.astype(str))\n",
    "print(ba_beers.dtypes,'\\n','\\n',rb_beers.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e9034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ba_ratings.dtypes,'\\n','\\n',rb_ratings.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829f7a29",
   "metadata": {},
   "source": [
    "The types of the values in the different columns of the different Dataframes seem appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51106efb",
   "metadata": {},
   "source": [
    "## Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf407145-0939-493e-a8b2-e119d2dd252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_beers['avg'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26f5ef0-12ec-4634-ac92-02d055a9166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_beers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df33c5a-1b5b-413e-b9fe-b81cddd7bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_beers_cleaned = ba_beers[~pd.isna(ba_beers['avg'])].reset_index() # avg = NaN valued beers are removed since there are not any reviews\n",
    "ba_beers_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd35d35-cef4-456e-bcfc-c484b5a7be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_beers_cleaned = rb_beers[~pd.isna(rb_beers['avg'])].reset_index() # avg = NaN valued beers are removed since there are not any reviews\n",
    "rb_beers_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619cb8e4-44d9-414b-a87e-6505e10eba4b",
   "metadata": {},
   "source": [
    "## Checking the correspondance between brewery_id in the beers DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcceec1-f245-4e9e-bf1a-fb94c6301d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_beers_cleaned[rb_beers_cleaned['brewery_id'] == 3198]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69267318-7a56-49d7-9458-b3e95d4e4c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_breweries[rb_breweries['id'] == 3198]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50493727-3c66-4c32-ace2-1a3d7d2b9de5",
   "metadata": {},
   "source": [
    "## Removing state information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899971b3-0e00-451f-ac25-9c1ce2010a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e6f570-cc1e-44fb-bf34-5e2b77b8fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_location(data_name):\n",
    "    data_name_c = data_name.copy()\n",
    "    for i in range(len(data_name['location'])):\n",
    "        if len(data_name['location'][i]) > 10:\n",
    "            if 'United States' in data_name['location'][i]: # Remove state names\n",
    "                data_name_c['location'][i] = 'United States'\n",
    "            elif ',' in data_name['location'][i]:\n",
    "                data_name_c['location'][i] = data_name['location'][i][:(data_name['location'][i].index(','))] # Removing for the double names ( such as 'United Kingdom,England' )\n",
    "            elif 'href' in data_name['location'][i]:\n",
    "                data_name_c.drop(i)\n",
    "    return data_name_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e238966-155a-4737-bfbf-20a5475c72f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_breweries_cleaned = edit_location(ba_breweries)\n",
    "rb_breweries_cleaned = edit_location(rb_breweries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5269ebee-1222-499d-b9b6-937b7c43ed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_breweries_cleaned['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77d65fb-c6a9-465f-9dfa-d5b6f16aa3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_breweries_cleaned['location'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b59c6fb-2bd9-4958-91aa-3c34a004de33",
   "metadata": {},
   "source": [
    "## Removing HTML links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76477d53-838e-42ce-809d-7a609f60b2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213ed318-0892-4c94-8cae-4eb22b041c81",
   "metadata": {},
   "source": [
    "## Removing the countries who have too few reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465fbcb3-70c6-49fb-94eb-b124240f9000",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_users_cleaned = ba_users[~pd.isna(ba_users['location'])].reset_index() # location = NaN valued users are removed\n",
    "rb_users_cleaned = rb_users[~pd.isna(rb_users['location'])].reset_index() # location = NaN valued users are removed\n",
    "ba_users_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e038006d-748d-4c42-8243-1abd5def6c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_users_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8833e788-2397-453e-b37d-90eadf6abe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_users_cleaned_2 = edit_location(ba_users_cleaned)\n",
    "rb_users_cleaned_2 = edit_location(rb_users_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a85db20-cd99-4bfa-b3f7-bb2c65ce1e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_users_cleaned_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3981101-e664-43f6-bf59-5c105a2b0fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = rb_users_cleaned_2['location'].value_counts() < 10 # We have to adjust the thresholds\n",
    "count[count == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e37bb7-d64e-43cf-8b69-f097497b35c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_users_cleaned_2_copy = rb_users_cleaned_2.copy(deep=True)\n",
    "for i in range(len(rb_users_cleaned_2['location'])):\n",
    "    if rb_users_cleaned_2['location'][i] in count :\n",
    "        rb_users_cleaned_2_copy.drop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bad225-07fd-4972-96d0-52cd42e322ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_users_cleaned_2_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b27fb-1caf-4d92-b9e4-c02281874ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count2 = ba_users_cleaned_2['location'].value_counts() < 10 # We have to adjust the thresholds\n",
    "count2[count2 == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c47951-e088-4126-bcd2-7e4fcffdbb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_users_cleaned_2_copy = ba_users_cleaned_2.copy(deep=True)\n",
    "for i in range(len(ba_users_cleaned_2['location'])):\n",
    "    if ba_users_cleaned_2['location'][i] in count2 :\n",
    "        ba_users_cleaned_2_copy.drop(i)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce2be1-cd21-4400-805f-1c12068dc806",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_users_cleaned_2_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb29d145",
   "metadata": {},
   "source": [
    "# 1) Link between culture and taste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6980f367",
   "metadata": {},
   "source": [
    "## a) Beer style preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8304fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use clustering techniques to determine beer style is most popular in each country / geographic area\n",
    "# use time information to determine if regional beer style preferences are stable (which would suggest that they are \n",
    "# strongly affected by culture)or if they vary over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ac60a3",
   "metadata": {},
   "source": [
    "## b) Importance of specific beer attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b5157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform linear regression between attribute ratings the final rating for all countries together and compare coefficients for each attribute\n",
    "# perform linear regression between attribute ratings the final rating for the different countries separately and observe the distribution of the coefficients for the different attributes across countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf205f2",
   "metadata": {},
   "source": [
    "# 2) Location-related biases in ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602da5a1",
   "metadata": {},
   "source": [
    "## a) Cultural biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47a927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the final rating for each country/ geographic area\n",
    "# determine if the final rating for each country/ geographic area is the same using statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a29b4b2",
   "metadata": {},
   "source": [
    "## b) Beer origin bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32502ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the final rating of domestic vs foreign beers and determine if there is a significant difference using statistical tests\n",
    "# determine if the final rating of a given beer is correlated with the number of reviewers from the country where the beer comes from who reviewed that beer (scatter plot + Pearson’s correlation coefficient + regression)\n",
    "# isolate beer enthusiasts (who wrote a very large number of reviews) and compare the final rating of domestic vs foreign beers and determine if there is a significant difference using statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4367514f",
   "metadata": {},
   "source": [
    "# 3) Other biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1c66a0",
   "metadata": {},
   "source": [
    "## a) Seasonal biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dec6525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the time information to determine the season during which each rating was posted (only consider countries with 4 seasons)\n",
    "# group ratings by season\n",
    "# within each group, determine the average final rating of each beer style\n",
    "# compare the results for the different seasons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93157f3c",
   "metadata": {},
   "source": [
    "## b) Experience biais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate users who gave a lot of ratings (based on a chosen threshold)\n",
    "# for each user, sort their reviews chronologically and assign an \"experience level\" (predefined values that will be the same for all users: n<o<p) to each rating based the count of reviews posted by that user up to that rating: new reviewer (for the first n reviews), amateur (for the n+1 th review up to the oth review), expert (for the o+1 th review until the last review)\n",
    "# calculate the average final rating for each experience level across all users\n",
    "# represent results as a bar plot\n",
    "# if a particular trend is visible,perform a paired t-test (for early vs. late reviews by the same user) to test if the rating decrease or increase is statistically significant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
